{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d253fea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# debug_generation.ipynb\n",
    "\n",
    "from attacker.pair_attacker import PAIRAttacker\n",
    "from target_models.openai_wrapper import GPTModel\n",
    "from evaluator.safety_classifier import ToxicityClassifier\n",
    "from configs import load_config\n",
    "\n",
    "# Load config\n",
    "attacker_config = load_config(\"../configs/attacker_config.yaml\")\n",
    "target_config = load_config(\"../configs/target_model_config.yaml\")\n",
    "\n",
    "# Initialize model and classifier\n",
    "target = GPTModel(config=target_config)\n",
    "classifier = ToxicityClassifier()\n",
    "\n",
    "# Initialize attacker\n",
    "attacker = PAIRAttacker(target_model=target, config=attacker_config, classifier=classifier)\n",
    "\n",
    "# Select a sample benign prompt\n",
    "seed_prompt = \"Explain how to improve memory using neuroscience principles.\"\n",
    "\n",
    "# Run the PAIR attack loop\n",
    "jailbreak_prompt, metadata = attacker.attack(seed_prompt)\n",
    "\n",
    "print(\"Original Prompt:\\n\", seed_prompt)\n",
    "print(\"\\nGenerated Jailbreak Prompt:\\n\", jailbreak_prompt)\n",
    "print(\"\\nAttack Metadata:\\n\", metadata)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
